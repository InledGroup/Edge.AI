# Tarea: Web Search como Proveedor de Contexto RAG

**Estado:** âœ… ImplementaciÃ³n Core Completada
**Fecha inicio:** 2025-12-24
**Fecha completaciÃ³n core:** 2025-12-24

## Objetivo

Implementar un sistema de bÃºsqueda web que permita al navegador obtener informaciÃ³n de internet y procesarla localmente como documentos temporales en el pipeline RAG existente.

## Principios ArquitectÃ³nicos

### âœ… LO QUE ES

- BÃºsqueda asistida controlada por el navegador
- ExtensiÃ³n del pipeline RAG existente
- Documentos temporales procesados localmente
- Sistema transparente y explicable

### âŒ LO QUE NO ES

- Agente autÃ³nomo que navega
- Sistema de crawling
- API externa de bÃºsqueda
- Scraping agresivo

## SeparaciÃ³n de Responsabilidades

| Componente | Responsabilidad | NO hace |
|------------|----------------|---------|
| **LLM** | Generar query de bÃºsqueda<br>Seleccionar URLs relevantes<br>Analizar contenido | âŒ Fetch<br>âŒ Navegar<br>âŒ Llamar APIs |
| **Navegador** | Realizar fetch<br>Descargar pÃ¡ginas<br>Ejecutar en Workers | âŒ Razonar<br>âŒ Decidir relevancia |
| **RAG** | Chunking<br>Embeddings<br>Vector search | âŒ BÃºsqueda web<br>âŒ Parsing HTML |

## Arquitectura TÃ©cnica

### Flujo Completo (8 Pasos)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 1: Query Generation (LLM)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Usuario: "Â¿CuÃ¡l es el Ãºltimo framework de JS en 2025?"
   â†“
LLM genera query optimizada: "latest javascript framework 2025"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 2: BÃºsqueda Web (NAVEGADOR)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
WebSearchService.search(query)
   â†“
Fuentes permitidas:
  - Wikipedia (es.wikipedia.org/w/api.php)
  - DuckDuckGo HTML (html.duckduckgo.com)
   â†“
Retorna: SearchResult[] {
  title: string,
  snippet: string,
  url: string
}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 3: SelecciÃ³n de Resultados (LLM)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
LLM recibe lista de tÃ­tulos + snippets
   â†“
Prompt: "Selecciona los 2 resultados mÃ¡s relevantes"
   â†“
LLM retorna: [0, 2] (Ã­ndices)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 4: Fetch Controlado (NAVEGADOR)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
WebSearchWorker.fetchPages(selectedUrls)
   â†“
LÃ­mites:
  - Max 3 URLs
  - Max 500KB por pÃ¡gina
  - Timeout: 10s por pÃ¡gina
  - Solo HTML pÃºblico
   â†“
Descarga SOLO las URLs seleccionadas

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 5: Limpieza de Contenido                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ContentExtractor.extract(html)
   â†“
Elimina:
  - <script>, <style>
  - <nav>, <header>, <footer>
  - ads, banners
   â†“
Extrae:
  - Texto visible
  - TÃ­tulos (h1-h6)
  - PÃ¡rrafos estructurados
   â†“
Retorna: CleanedContent {
  text: string,
  title: string,
  url: string
}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 6: Chunking + Embeddings (RAG EXISTENTE)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
processWebDocument(content)
   â†“
REUTILIZA:
  - semanticChunkText() â†’ chunks
  - generateEmbeddingsBatch() â†’ embeddings
   â†“
Documentos TEMPORALES (no persistidos por defecto)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 7: RecuperaciÃ³n (RAG EXISTENTE)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
searchSimilarChunks(queryEmbedding, topK=3)
   â†“
Vector search local
   â†“
Retorna top-3 chunks mÃ¡s relevantes

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASO 8: Respuesta Final (LLM)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
buildRAGPrompt(query, context)
   â†“
LLM genera respuesta SOLO con contexto recuperado
   â†“
Incluye referencias a URLs usadas
```

## Estructura de Archivos

```
src/lib/web-search/
â”œâ”€â”€ web-search.ts              # Servicio principal de bÃºsqueda web
â”œâ”€â”€ content-extractor.ts       # Limpieza de HTML â†’ texto
â”œâ”€â”€ search-providers.ts        # Implementaciones de bÃºsqueda (Wikipedia, DDG)
â”œâ”€â”€ web-document-processor.ts  # IntegraciÃ³n con RAG pipeline
â””â”€â”€ types.ts                   # Tipos especÃ­ficos

src/lib/workers/
â””â”€â”€ web-search.worker.ts       # Worker para fetch controlado

src/lib/rag/
â””â”€â”€ web-rag-integration.ts     # Puente entre web search y RAG existente
```

## Tipos Clave

```typescript
// Resultado de bÃºsqueda web
interface SearchResult {
  title: string;
  snippet: string;
  url: string;
  source: 'wikipedia' | 'duckduckgo';
}

// Contenido limpio extraÃ­do
interface CleanedContent {
  text: string;
  title: string;
  url: string;
  extractedAt: number;
  wordCount: number;
}

// Documento web temporal
interface WebDocument {
  id: string;
  type: 'web';
  content: string;
  url: string;
  title: string;
  fetchedAt: number;
  temporary: true; // No se persiste en IndexedDB
}

// Resultado completo de bÃºsqueda web + RAG
interface WebRAGResult {
  query: string;
  searchResults: SearchResult[];
  selectedUrls: string[];
  cleanedContents: CleanedContent[];
  ragResult: RAGResult; // Del pipeline existente
  totalTime: number;
}
```

## LÃ­mites y Restricciones

### LÃ­mites TÃ©cnicos

- **Max resultados de bÃºsqueda:** 10
- **Max URLs descargadas:** 3
- **Max tamaÃ±o por pÃ¡gina:** 500KB
- **Timeout por fetch:** 10s
- **Max chunks por documento web:** 20
- **Top-K en retrieval:** 3-5

### Restricciones de Seguridad

- Solo HTTP/HTTPS
- No ejecutar JavaScript de pÃ¡ginas
- No seguir redirects automÃ¡ticos cross-domain
- Respetar Content-Type (solo text/html)
- User-Agent identificable

### Fuentes Permitidas

1. **Wikipedia**
   - API pÃºblica
   - Contenido estructurado
   - Sin rate limits estrictos

2. **DuckDuckGo HTML**
   - BÃºsqueda pÃºblica
   - Sin JavaScript necesario
   - Parsing simple

## Checklist de ImplementaciÃ³n

### Fase 1: MÃ³dulo de BÃºsqueda Web âœ…
- [x] Implementar `WebSearchService` en `web-search.ts`
- [x] Crear provider de Wikipedia
- [x] Crear provider de DuckDuckGo HTML
- [x] Implementar rate limiting bÃ¡sico
- [x] Cache de resultados (5 min TTL)

### Fase 2: ExtracciÃ³n de Contenido âœ…
- [x] Implementar `ContentExtractor` en `content-extractor.ts`
- [x] Parser HTML â†’ texto limpio
- [x] Eliminar elementos no deseados (scripts, ads, nav)
- [x] Preservar estructura (tÃ­tulos, pÃ¡rrafos)
- [x] ExtracciÃ³n de metadata (autor, fecha, descripciÃ³n)

### Fase 3: Web Worker âœ…
- [x] Crear `web-search.worker.ts`
- [x] Implementar fetch controlado con timeouts
- [x] Sistema de mensajerÃ­a request-response
- [x] Manejo de errores (404, timeout, CORS)
- [x] WebSearchWorkerManager integrado en WorkerPool

### Fase 4: IntegraciÃ³n RAG âœ…
- [x] Crear `WebRAGOrchestrator` (orquestador principal)
- [x] Reutilizar `semanticChunkText()`
- [x] Reutilizar `generateEmbeddingsBatch()`
- [x] Documentos temporales WebDocument
- [x] Vector search local con cosine similarity

### Fase 5: Prompts LLM âœ…
- [x] Prompt para generar query de bÃºsqueda
- [x] Prompt para seleccionar URLs relevantes
- [x] Prompt para respuesta final con contexto web
- [x] ValidaciÃ³n de respuestas JSON del LLM
- [x] Fallback automÃ¡tico si parsing falla

### Fase 6: UI y UX â³
- [ ] Toggle "Buscar en web" en chat
- [ ] Indicador visual durante bÃºsqueda
- [ ] Mostrar URLs consultadas
- [ ] Mostrar snippets de contenido usado
- [ ] Transparencia: "Analizado por tu navegador"

### Fase 7: Testing â³
- [ ] Test end-to-end con query real
- [ ] Test con timeout/errores
- [ ] Test con mÃºltiples proveedores
- [ ] Test de lÃ­mites (tamaÃ±o, cantidad)
- [ ] Test de integraciÃ³n con RAG

### Fase 8: DocumentaciÃ³n âœ…
- [x] Comentarios en cÃ³digo (TSDoc completo)
- [x] Arquitectura detallada (arquitectura.md)
- [x] Ejemplos de uso (ejemplos-uso.md)
- [x] Tipos TypeScript completos

## MÃ©tricas de Ã‰xito

- âœ… BÃºsqueda web funciona sin APIs externas
- âœ… LLM NUNCA hace fetch directo
- âœ… Pipeline RAG se reutiliza 100%
- âœ… Documentos web NO se persisten por defecto
- âœ… Usuario ve claramente quÃ© URLs se consultaron
- âœ… Tiempo total < 30s para query tÃ­pico
- âœ… Sistema funciona offline despuÃ©s de bÃºsqueda

## Notas TÃ©cnicas

### CORS y Limitaciones

Algunos sitios bloquearÃ¡n fetch desde el navegador por CORS. Estrategias:

1. **Priorizar fuentes CORS-friendly:**
   - Wikipedia API âœ…
   - Sitios con `Access-Control-Allow-Origin: *`

2. **Fallback graceful:**
   - Si URL falla por CORS, mostrar error claro
   - Intentar con siguiente URL
   - No bloquear todo el flujo

3. **NO usar proxies:**
   - Contradice principio local-first
   - Introduce dependencia externa

### Temporalidad de Documentos

Por defecto, documentos web son temporales:

```typescript
{
  temporary: true,  // No se guarda en IndexedDB
  ttl: 3600000     // 1 hora en memoria
}
```

OpciÃ³n futura: permitir "guardar fuente web" explÃ­citamente.

### Transparencia

Cada respuesta con contexto web debe mostrar:

```
ğŸ“ Fuentes consultadas:
  â€¢ Wikipedia: "JavaScript" (https://es.wikipedia.org/wiki/JavaScript)
  â€¢ MDN Web Docs: "What is JavaScript?" (https://developer.mozilla.org/...)

ğŸ’¡ Esta informaciÃ³n fue analizada localmente por tu navegador.
   No se enviÃ³ ningÃºn dato a servidores externos.
```

## Riesgos y Mitigaciones

| Riesgo | MitigaciÃ³n |
|--------|------------|
| CORS bloquea fetch | Priorizar fuentes CORS-friendly, fallback claro |
| PÃ¡ginas muy grandes | LÃ­mite 500KB, timeout 10s |
| HTML mal formado | Parser robusto, try-catch, fallback a texto plano |
| LLM genera URLs invÃ¡lidas | ValidaciÃ³n antes de fetch |
| Contenido irrelevante | LLM selecciona antes de fetch |
| Sobrecarga de red | Max 3 URLs, rate limiting |

## Referencias

- Pipeline RAG existente: `src/lib/rag/rag-pipeline.ts`
- Vector search: `src/lib/rag/vector-search.ts`
- Workers: `src/lib/workers/`
- Chunking semÃ¡ntico: `src/lib/rag/semantic-chunking.ts`

---

**Ãšltima actualizaciÃ³n:** 2025-12-24
