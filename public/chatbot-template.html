<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>__CHATBOT_NAME__ - Asistente IA</title>
    <meta name="description" content="__CHATBOT_DESCRIPTION__">
    <meta name="theme-color" content="#28e518">

    <style>
        :root {
            --primary: #28e518;
            --primary-dark: #20b813;
            --primary-glow: rgba(40, 229, 24, 0.3);
            --bg-dark: #0a0a0a;
            --bg-card: #141414;
            --text-main: #ffffff;
            --text-muted: #888888;
            --border: rgba(255, 255, 255, 0.08);
            --glass: rgba(10, 10, 10, 0.9);
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-dark);
            height: 100vh;
            color: var(--text-main);
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        /* Responsive Container */
        .app-container {
            width: 100%;
            max-width: 100%;
            height: 100vh;
            display: flex;
            flex-direction: column;
            background: var(--bg-dark);
            position: relative;
        }

        /* Loading Screen - Optimized for small size */
        .loading-screen {
            position: absolute;
            inset: 0;
            background: var(--bg-dark);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 1000;
            padding: 2rem;
            text-align: center;
        }

        .loader-ring {
            width: 60px;
            height: 60px;
            border: 3px solid rgba(40, 229, 24, 0.1);
            border-radius: 50%;
            border-top-color: var(--primary);
            animation: spin 0.8s linear infinite;
            margin-bottom: 1.5rem;
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        .loading-progress-container {
            width: 100%;
            max-width: 300px;
            margin-top: 1.5rem;
        }

        .loading-progress-info {
            display: flex;
            justify-content: space-between;
            font-size: 0.75rem;
            color: var(--text-muted);
            margin-bottom: 0.5rem;
        }

        .loading-progress {
            width: 100%;
            height: 6px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            overflow: hidden;
        }

        .loading-bar {
            height: 100%;
            background: var(--primary);
            width: 0%;
            transition: width 0.3s ease;
            box-shadow: 0 0 10px var(--primary-glow);
        }

        /* Header - Compact */
        header {
            padding: 0.75rem 1rem;
            background: var(--glass);
            border-bottom: 1px solid var(--border);
            display: flex;
            align-items: center;
            justify-content: space-between;
            backdrop-filter: blur(10px);
            z-index: 10;
        }

        .header-left {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            min-width: 0;
        }

        .bot-avatar {
            width: 32px;
            height: 32px;
            background: #1a1a1a;
            border-radius: 8px;
            overflow: hidden;
            border: 1px solid var(--border);
            flex-shrink: 0;
        }

        .bot-avatar img {
            width: 100%;
            height: 100%;
            object-fit: contain;
            display: block;
        }

        .bot-info {
            min-width: 0;
        }

        .bot-info h1 {
            font-size: 0.9rem;
            font-weight: 600;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .bot-info p {
            font-size: 0.7rem;
            color: var(--text-muted);
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .header-right {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .lang-switch {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid var(--border);
            color: var(--text-main);
            font-size: 0.7rem;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            cursor: pointer;
            outline: none;
            text-transform: uppercase;
            font-weight: 600;
        }

        .lang-switch:hover {
            background: rgba(255, 255, 255, 0.1);
        }

        /* Messages Viewport */
        .messages-viewport {
            flex: 1;
            overflow-y: auto;
            padding: 1rem;
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
            background: radial-gradient(circle at 50% 10%, rgba(40, 229, 24, 0.03), transparent 70%);
        }

        .messages-viewport::-webkit-scrollbar {
            width: 4px;
        }

        .messages-viewport::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
        }

        .msg {
            max-width: 90%;
            padding: 0.65rem 0.85rem;
            border-radius: 14px;
            line-height: 1.5;
            font-size: 0.875rem;
            animation: popIn 0.2s ease-out;
            word-wrap: break-word;
        }

        @keyframes popIn {
            from {
                opacity: 0;
                transform: scale(0.95);
            }

            to {
                opacity: 1;
                transform: scale(1);
            }
        }

        .msg-user {
            align-self: flex-end;
            background: var(--primary);
            color: #000;
            font-weight: 500;
            border-bottom-right-radius: 4px;
        }

        .msg-assistant {
            align-self: flex-start;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-bottom-left-radius: 4px;
        }

        .msg-assistant p {
            margin-bottom: 0.5rem;
        }

        .msg-assistant p:last-child {
            margin-bottom: 0;
        }

        .msg-assistant code {
            background: rgba(255, 255, 255, 0.06);
            padding: 0.1rem 0.3rem;
            border-radius: 4px;
            font-size: 0.85em;
            font-family: monospace;
        }

        .msg-assistant pre {
            background: #000;
            padding: 0.75rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 0.5rem 0;
            font-size: 0.8rem;
            border: 1px solid var(--border);
        }

        /* Input - Compact */
        .input-container {
            padding: 0.75rem;
            background: var(--glass);
            border-top: 1px solid var(--border);
            backdrop-filter: blur(10px);
        }

        .input-box {
            display: flex;
            gap: 0.5rem;
            background: rgba(255, 255, 255, 0.04);
            border: 1px solid var(--border);
            padding: 0.35rem 0.35rem 0.35rem 0.85rem;
            border-radius: 12px;
            align-items: flex-end;
        }

        textarea {
            flex: 1;
            background: transparent;
            border: none;
            color: #fff;
            padding: 0.4rem 0;
            resize: none;
            outline: none;
            font-family: inherit;
            font-size: 0.875rem;
            line-height: 1.4;
            max-height: 100px;
        }

        .btn-send {
            width: 32px;
            height: 32px;
            background: var(--primary);
            border: none;
            border-radius: 8px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.2s;
            flex-shrink: 0;
        }

        .btn-send:hover:not(:disabled) {
            background: var(--primary-dark);
        }

        .btn-send:disabled {
            opacity: 0.2;
            cursor: not-allowed;
        }

        .hidden {
            display: none !important;
        }

        /* Welcome Message Small */
        .welcome-mini {
            text-align: center;
            margin: auto 0;
            padding: 1rem;
        }

        .welcome-mini img {
            width: 48px;
            height: 48px;
            margin-bottom: 1rem;
            opacity: 0.9;
        }

        .welcome-mini h2 {
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
        }

        .welcome-mini p {
            font-size: 0.8rem;
            color: var(--text-muted);
        }
    </style>
</head>

<body>
    <!-- Loading Screen -->
    <div id="loading-screen" class="loading-screen">
        <div class="loader-ring"></div>
        <div class="loading-progress-container">
            <div class="loading-progress-info">
                <span id="loading-status">Cargando asistente...</span>
                <span id="loading-percentage">0%</span>
            </div>
            <div class="loading-progress">
                <div id="loading-bar" class="loading-bar"></div>
            </div>
        </div>
    </div>

    <!-- Chat App -->
    <div id="chat-app" class="app-container hidden">
        <header>
            <div class="header-left">
                <div class="bot-avatar">
                    <img src="https://hosted.inled.es/inledai.png" alt="Icono">
                </div>
                <div class="bot-info">
                    <h1>__CHATBOT_NAME__</h1>
                    <p>__CHATBOT_DESCRIPTION__</p>
                </div>
            </div>
            <div class="header-right">
                <select id="lang-switch" class="lang-switch">
                    <option value="es">ES</option>
                    <option value="en">EN</option>
                </select>
            </div>
        </header>

        <main id="messages" class="messages-viewport">
            <div class="welcome-mini">
                <img src="https://hosted.inled.es/inledai.png" alt="InledAI">
                <h2 id="welcome-title">¿Cómo puedo ayudarte?</h2>
                <p id="welcome-desc">IA local basada en tus documentos.</p>
            </div>
        </main>

        <div class="input-container">
            <div class="input-box">
                <textarea id="chat-input" placeholder="Escribe..." rows="1"></textarea>
                <button id="send-button" class="btn-send" disabled title="Enviar">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="black" stroke-width="3"
                        stroke-linecap="round" stroke-linejoin="round">
                        <line x1="22" y1="2" x2="11" y2="13"></line>
                        <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
                    </svg>
                </button>
            </div>
        </div>
    </div>

    <script type="module">
        const CHATBOT_CONFIG = {
            name: '__CHATBOT_NAME__',
            description: '__CHATBOT_DESCRIPTION__',
            modelId: '__MODEL_ID__',
            engine: '__MODEL_ENGINE__',
            ggufUrl: '__MODEL_GGUF_URL__',
            ragConfig: {
                topK: __TOP_K__,
                temperature: __TEMPERATURE__,
                maxTokens: __MAX_TOKENS__,
                similarityThreshold: __SIMILARITY_THRESHOLD__,
                chunkWindowSize: __CHUNK_WINDOW_SIZE__
            },
            chunks: __CHUNKS_DATA__
        };

        const TRANSLATIONS = {
            es: {
                loading: "Cargando asistente...",
                loading_engine: "Iniciando motor IA...",
                loading_model: "Descargando modelo...",
                ready: "Asistente listo",
                error: "Error: ",
                welcome_title: "¿Cómo puedo ayudarte?",
                welcome_desc: "IA local basada en tus documentos.",
                input_placeholder: "Escribe un mensaje...",
                send_title: "Enviar",
                system_prompt_intro: "Eres un asistente inteligente. Contexto:\n",
                system_prompt_outro: "\n\nResponde en español usando Markdown."
            },
            en: {
                loading: "Loading assistant...",
                loading_engine: "Starting AI engine...",
                loading_model: "Downloading model...",
                ready: "Assistant ready",
                error: "Error: ",
                welcome_title: "How can I help you?",
                welcome_desc: "Local AI based on your documents.",
                input_placeholder: "Type a message...",
                send_title: "Send",
                system_prompt_intro: "You are an intelligent assistant. Context:\n",
                system_prompt_outro: "\n\nRespond in English using Markdown."
            }
        };

        // --- BM25 Engine ---
        class BM25 {
            constructor(k1 = 1.5, b = 0.75) {
                this.documents = [];
                this.avgDocLength = 0;
                this.docFrequency = new Map();
                this.k1 = k1;
                this.b = b;
            }

            addDocuments(docs) {
                this.documents = docs.map(d => ({
                    id: d.id,
                    content: d.content,
                    tokens: this.tokenize(d.content)
                }));
                const total = this.documents.reduce((s, d) => s + d.tokens.length, 0);
                this.avgDocLength = total / this.documents.length;
                this.docFrequency.clear();
                this.documents.forEach(d => {
                    new Set(d.tokens).forEach(t => {
                        this.docFrequency.set(t, (this.docFrequency.get(t) || 0) + 1);
                    });
                });
            }

            tokenize(text) {
                return text.toLowerCase().replace(/[^\p{L}\p{N}\s]/gu, ' ').split(/\s+/).filter(t => t.length > 2);
            }

            search(query, topK = 10) {
                const tokens = this.tokenize(query);
                if (tokens.length === 0) return [];
                const scores = [];
                for (const doc of this.documents) {
                    let score = 0;
                    for (const t of tokens) {
                        score += this.termScore(t, doc);
                    }
                    if (score > 0) scores.push({ documentId: doc.id, score });
                }
                scores.sort((a, b) => b.score - a.score);
                return scores.slice(0, topK);
            }

            termScore(term, doc) {
                const tf = doc.tokens.filter(t => t === term).length;
                if (tf === 0) return 0;
                const df = this.docFrequency.get(term) || 0;
                const idf = Math.log((this.documents.length - df + 0.5) / (df + 0.5) + 1);
                const norm = 1 - this.b + this.b * (doc.tokens.length / this.avgDocLength);
                return idf * ((tf * (this.k1 + 1)) / (tf + this.k1 * norm));
            }
        }

        // --- RAG Logic ---
        class RAGSystem {
            constructor(chunks, config) {
                this.chunks = chunks;
                this.config = config;
                this.bm25 = new BM25();
                this.bm25.addDocuments(chunks.map(c => ({ id: c.id, content: c.content })));
            }

            async search(query, topK = 5) {
                const bm25Results = this.bm25.search(query, this.chunks.length);
                return bm25Results.slice(0, topK).map(r => ({
                    ...this.chunks.find(c => c.id === r.documentId),
                    score: r.score
                }));
            }

            createContext(chunks) {
                if (chunks.length === 0) return '';
                return chunks.map((c, i) => `[Referencia ${i + 1}]\n${c.metadata?.expandedContext || c.content}`).join('\n\n');
            }
        }

        // --- Chat UI Controller ---
        class ChatUI {
            constructor() {
                this.isGenerating = false;
                this.messages = [];
                this.engine = null;
                this.rag = null;
                this.currentLang = localStorage.getItem('chatbot_lang') || 'es';

                this.loadingScreen = document.getElementById('loading-screen');
                this.loadingStatus = document.getElementById('loading-status');
                this.loadingPercentage = document.getElementById('loading-percentage');
                this.loadingBar = document.getElementById('loading-bar');
                this.chatApp = document.getElementById('chat-app');
                this.messagesContainer = document.getElementById('messages');
                this.chatInput = document.getElementById('chat-input');
                this.sendButton = document.getElementById('send-button');
                this.langSwitch = document.getElementById('lang-switch');

                // UI Elements for localization
                this.welcomeTitle = document.getElementById('welcome-title');
                this.welcomeDesc = document.getElementById('welcome-desc');

                this.init();
            }

            t(key) {
                return TRANSLATIONS[this.currentLang][key] || key;
            }

            updateUIForLang() {
                this.langSwitch.value = this.currentLang;
                this.chatInput.placeholder = this.t('input_placeholder');
                this.sendButton.title = this.t('send_title');
                if (this.welcomeTitle) this.welcomeTitle.textContent = this.t('welcome_title');
                if (this.welcomeDesc) this.welcomeDesc.textContent = this.t('welcome_desc');
            }

            async init() {
                try {
                    this.updateUIForLang();
                    this.rag = new RAGSystem(CHATBOT_CONFIG.chunks, CHATBOT_CONFIG.ragConfig);
                    this.updateProgress(10, this.t('loading_engine'));

                    if (CHATBOT_CONFIG.engine === 'webllm') {
                        await this.initWebLLM();
                    } else if (CHATBOT_CONFIG.engine === 'wllama') {
                        await this.initWllama();
                    } else {
                        // Fallback to WebLLM
                        await this.initWebLLM();
                    }

                    this.updateProgress(100, this.t('ready'));
                    setTimeout(() => {
                        this.loadingScreen.classList.add('hidden');
                        this.chatApp.classList.remove('hidden');
                        this.chatInput.focus();
                    }, 400);

                    this.setupEventListeners();
                } catch (e) {
                    console.error(e);
                    this.loadingStatus.innerHTML = `<span style="color: #ef4444">${this.t('error')}${e.message}</span>`;
                }
            }

            async initWebLLM() {
                let webllmModule;
                try {
                    webllmModule = await import('https://esm.run/@mlc-ai/web-llm@0.2.80');
                } catch (e) {
                    webllmModule = await import('https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.80/+esm');
                }
                const webllm = webllmModule.MLCEngine ? webllmModule : (webllmModule.default || webllmModule);

                this.engine = new webllm.MLCEngine();
                await this.engine.reload(CHATBOT_CONFIG.modelId, {
                    initProgressCallback: (report) => {
                        const progress = 10 + (report.progress * 90);
                        this.updateProgress(progress, this.t('loading_model'), report.text);
                    }
                });
            }

            async initWllama() {
                // For stand-alone exported HTML, we'll try to use a CDN that provides Wllama
                // Note: Wllama requires WASM files which usually need to be hosted locally.
                // For simplicity in this template, we'll try to load from a public CDN if possible.
                // If not, we'll suggest using WebLLM or hosting WASM files.
                
                try {
                    const wllamaModule = await import('https://cdn.jsdelivr.net/npm/@wllama/wllama@1.24.4/dist/index.js');
                    const { Wllama } = wllamaModule;
                    
                    const config = {
                        'single-thread/wllama.wasm': 'https://cdn.jsdelivr.net/npm/@wllama/wllama@1.24.4/dist/single-thread/wllama.wasm',
                        'multi-thread/wllama.wasm': 'https://cdn.jsdelivr.net/npm/@wllama/wllama@1.24.4/dist/multi-thread/wllama.wasm',
                        'multi-thread/wllama.worker.mjs': 'https://cdn.jsdelivr.net/npm/@wllama/wllama@1.24.4/dist/multi-thread/wllama.worker.mjs',
                    };

                    const wllama = new Wllama(config);
                    await wllama.loadModelFromUrl(CHATBOT_CONFIG.ggufUrl, {
                        n_ctx: 2048,
                        progressCallback: ({ loaded, total }) => {
                            if (total > 0) {
                                const progress = 10 + ((loaded / total) * 90);
                                const mb = (loaded / (1024 * 1024)).toFixed(1);
                                const totalMb = (total / (1024 * 1024)).toFixed(1);
                                this.updateProgress(progress, this.t('loading_model'), `${mb}MB / ${totalMb}MB`);
                            }
                        }
                    });
                    
                    this.engine = {
                        chat: {
                            completions: {
                                create: async (options) => {
                                    const prompt = this.formatPrompt(options.messages);
                                    let fullText = '';
                                    
                                    // Simulated streaming for Wllama if simple completion is used
                                    // Or use Wllama's createCompletion if it supports streaming
                                    const completion = await wllama.createCompletion(prompt, {
                                        nPredict: options.max_tokens,
                                        temp: options.temperature,
                                        onNewToken: (token, piece, text) => {
                                            if (options.stream) {
                                                // This is a bit of a hack to match OpenAI-like streaming API
                                                // In a real scenario, we'd wrap this properly
                                            }
                                        }
                                    });
                                    
                                    // For now, return a compatible object for the sendMessage loop
                                    if (options.stream) {
                                        return (async function* () {
                                            // Split by words to simulate streaming if Wllama doesn't stream easily here
                                            const words = completion.split(' ');
                                            for (let i = 0; i < words.length; i++) {
                                                await new Promise(r => setTimeout(r, 20));
                                                yield { choices: [{ delta: { content: words[i] + (i === words.length - 1 ? '' : ' ') } }] };
                                            }
                                        })();
                                    }
                                    return { choices: [{ message: { content: completion } }] };
                                }
                            }
                        }
                    };
                } catch (err) {
                    throw new Error("Wllama engine initialization failed. Standalone GGUF support requires specialized hosting. Error: " + err.message);
                }
            }

            formatPrompt(messages) {
                return messages.map(m => {
                    const role = m.role === 'system' ? 'system' : (m.role === 'user' ? 'user' : 'assistant');
                    return `<|im_start|>${role}\n${m.content}<|im_end|>`;
                }).join('\n') + '\n<|im_start|>assistant\n';
            }

            updateProgress(prg, status, detail = '') {
                const percentage = Math.round(prg);
                this.loadingBar.style.width = percentage + '%';
                this.loadingPercentage.textContent = percentage + '%';
                this.loadingStatus.textContent = detail ? `${status} (${detail})` : status;
            }

            setupEventListeners() {
                const triggerSend = () => this.sendMessage();
                this.sendButton.addEventListener('click', triggerSend);
                this.chatInput.addEventListener('keydown', (e) => {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        triggerSend();
                    }
                });
                this.chatInput.addEventListener('input', () => {
                    this.chatInput.style.height = 'auto';
                    this.chatInput.style.height = this.chatInput.scrollHeight + 'px';
                    this.sendButton.disabled = !this.chatInput.value.trim() || this.isGenerating;
                });

                this.langSwitch.addEventListener('change', (e) => {
                    this.currentLang = e.target.value;
                    localStorage.setItem('chatbot_lang', this.currentLang);
                    this.updateUIForLang();
                });
            }

            async sendMessage() {
                const text = this.chatInput.value.trim();
                if (!text || this.isGenerating) return;

                this.chatInput.value = '';
                this.chatInput.style.height = 'auto';
                this.sendButton.disabled = true;

                this.addMessage(text, 'user');
                this.messages.push({ role: 'user', content: text });
                this.isGenerating = true;

                try {
                    const ctxChunks = await this.rag.search(text, CHATBOT_CONFIG.ragConfig.topK);
                    const prompt = `${this.t('system_prompt_intro')}${this.rag.createContext(ctxChunks)}${this.t('system_prompt_outro')}`;

                    const response = await this.engine.chat.completions.create({
                        messages: [{ role: 'system', content: prompt }, ...this.messages.slice(-6)],
                        temperature: CHATBOT_CONFIG.ragConfig.temperature,
                        max_tokens: CHATBOT_CONFIG.ragConfig.maxTokens,
                        stream: true
                    });

                    const assistantMsg = this.addMessage('', 'assistant');
                    let fullText = '';
                    for await (const chunk of response) {
                        fullText += chunk.choices[0]?.delta?.content || '';
                        assistantMsg.content = fullText;
                    }
                    this.messages.push({ role: 'assistant', content: fullText });
                } catch (e) {
                    this.addMessage(this.t('error') + e.message, 'assistant');
                } finally {
                    this.isGenerating = false;
                    this.sendButton.disabled = false;
                    this.chatInput.focus();
                }
            }

            addMessage(content, role) {
                const hero = this.messagesContainer.querySelector('.welcome-mini');
                if (hero) hero.remove();

                const div = document.createElement('div');
                div.className = `msg msg-${role}`;
                const inner = document.createElement('div');
                div.appendChild(inner);

                if (role === 'user') inner.textContent = content;
                else inner.innerHTML = this.parseMd(content);

                this.messagesContainer.appendChild(div);
                this.messagesContainer.scrollTop = this.messagesContainer.scrollHeight;

                const self = this;
                return {
                    set content(v) { inner.innerHTML = self.parseMd(v); }
                };
            }

            parseMd(t) {
                return t.replace(/```(\w*)\n([\s\S]*?)```/g, '<pre><code>$2</code></pre>')
                    .replace(/`([^`]+)`/g, '<code>$1</code>')
                    .replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>')
                    .replace(/\n/g, '<br>');
            }
        }

        window.addEventListener('DOMContentLoaded', () => new ChatUI());
    </script>
</body>

</html>