# Sistema de ConfiguraciÃ³n de Modelos de IA

Sistema completo de configuraciÃ³n, selecciÃ³n y persistencia de modelos de IA para Edge.AI, una plataforma 100% en navegador con ejecuciÃ³n local de modelos.

## ğŸ“‹ Ãndice

1. [Arquitectura General](#arquitectura-general)
2. [MÃ³dulos del Sistema](#mÃ³dulos-del-sistema)
3. [Flujo de Usuario](#flujo-de-usuario)
4. [CatÃ¡logo de Modelos](#catÃ¡logo-de-modelos)
5. [Sistema de Scoring](#sistema-de-scoring)
6. [Componentes UI](#componentes-ui)
7. [Uso y ExtensiÃ³n](#uso-y-extensiÃ³n)

---

## ğŸ—ï¸ Arquitectura General

El sistema estÃ¡ diseÃ±ado con separaciÃ³n de responsabilidades:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FLUJO COMPLETO                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Primera ejecuciÃ³n                Ejecuciones posteriores  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                             â”‚
â”‚  1. Detectar capabilities         1. Cargar settings       â”‚
â”‚  2. Mostrar FirstRunWizard         2. Cargar modelo defaultâ”‚
â”‚  3. Scoring de modelos             3. Continuar normal     â”‚
â”‚  4. Usuario selecciona                                     â”‚
â”‚  5. Cargar modelos                ReconfiguraciÃ³n manual:  â”‚
â”‚  6. Guardar en localStorage        â†’ ModelConfigMenu       â”‚
â”‚  7. Marcar setup completo          â†’ Abrir wizard          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TecnologÃ­as Utilizadas

- **DetecciÃ³n de hardware**: WebGPU API, Navigator APIs
- **EjecuciÃ³n de modelos**: WebLLM (GPU) + Wllama (CPU/WASM)
- **Persistencia**: localStorage
- **UI**: Preact + TypeScript
- **Estado**: Preact Signals

---

## ğŸ§© MÃ³dulos del Sistema

### 1. `device-profile.ts` - DetecciÃ³n de Capacidades

**PropÃ³sito**: Detectar automÃ¡ticamente las capacidades del dispositivo del usuario.

**Funciones principales**:

```typescript
detectDeviceProfile(): Promise<DeviceProfile>
```

**Detecta**:
- Disponibilidad de WebGPU
- Tier de GPU (low/medium/high)
- Memoria RAM disponible
- Cores lÃ³gicos del CPU
- Soporte de SharedArrayBuffer
- Soporte de WASM threads

**Salida**: Objeto `DeviceProfile` con:
```typescript
{
  hasWebGPU: boolean;
  gpuTier?: 'low' | 'medium' | 'high';
  memoryGB: number;
  estimatedAvailableMemoryGB: number;
  logicalCores: number;
  hasSharedArrayBuffer: boolean;
  hasWASMThreads: boolean;
  recommendedBackend: 'webgpu' | 'wasm' | 'cpu';
  deviceClass: 'high-end' | 'mid-range' | 'low-end';
}
```

---

### 2. `model-registry.ts` - CatÃ¡logo de Modelos

**PropÃ³sito**: Registro centralizado de modelos disponibles con metadatos completos.

**Estructura de cada modelo**:

```typescript
{
  id: string;                    // Identificador Ãºnico
  name: string;                  // Nombre tÃ©cnico
  displayName: string;           // Nombre para UI
  description: string;           // DescripciÃ³n clara
  type: 'chat' | 'embedding';
  engine: 'webllm' | 'wllama';
  webllmModelId?: string;        // Para WebLLM/MLC
  ggufUrl?: string;              // Para Wllama/GGUF
  sizeGB: number;
  speed: 'very-fast' | 'fast' | 'medium' | 'slow';
  quality: 'basic' | 'good' | 'excellent';
  quantization?: 'q4' | 'q5' | 'q8' | 'f16';
  minMemoryGB: number;
  preferredMemoryGB: number;
  requiresWebGPU: boolean;
  contextSize: number;
  tags: string[];
}
```

**Modelos incluidos**:

#### Chat - PequeÃ±os (< 1GB)
- SmolLM2 135M - Ultra rÃ¡pido, bÃ¡sico
- SmolLM2 360M - RÃ¡pido, equilibrado
- Qwen2.5 0.5B - Ligero de Alibaba

#### Chat - Medianos (1-2GB)
- TinyLlama 1.1B - Basado en Llama
- Llama 3.2 1B - Alta calidad de Meta
- Qwen2.5 1.5B - **Recomendado** equilibrio

#### Chat - Grandes (3GB+)
- Llama 3.2 3B - MÃ¡xima calidad
- Phi 3.5 Mini - Razonamiento avanzado

#### Embeddings
- Qwen2 0.5B - Para bÃºsqueda semÃ¡ntica

---

### 3. `model-scoring.ts` - Sistema de PuntuaciÃ³n

**PropÃ³sito**: Calcular compatibilidad de modelos segÃºn el hardware del usuario.

**FunciÃ³n principal**:

```typescript
scoreModel(model: ModelMetadata, device: DeviceProfile): ModelScore
```

**Algoritmo de scoring** (0-100%):

1. **Memoria** (crÃ­tico):
   - -50 si no hay memoria mÃ­nima
   - -20 si memoria justa
   - +0 si suficiente

2. **WebGPU**:
   - -60 si modelo requiere GPU pero no hay
   - +10 si hay GPU y se aprovecha

3. **GPU Tier**:
   - +15 para GPU high-end
   - +5 para medium
   - -10 para low

4. **Ratio de uso de memoria**:
   - +5 si modelo es ligero (< 30% de RAM)
   - -15 si modelo es pesado (> 70% de RAM)

5. **CPU cores** (para modelos sin GPU):
   - +5 si multi-core
   - -10 si pocos cores

6. **WASM threads**:
   - +5 si disponible para Wllama
   - -10 si no disponible

7. **Bonificaciones por device class**:
   - +10 para combinaciones Ã³ptimas

**Salida**:

```typescript
{
  model: ModelMetadata;
  score: number;              // 0-100
  confidence: 'high' | 'medium' | 'low';
  reasons: string[];          // Razones positivas
  warnings: string[];         // Advertencias
  recommendation: 'excellent' | 'good' | 'usable' | 'not-recommended';
}
```

---

### 4. `model-settings.ts` - Persistencia

**PropÃ³sito**: Guardar y cargar configuraciÃ³n del usuario en localStorage.

**Funciones**:

```typescript
// Obtener configuraciÃ³n actual
getModelSettings(): ModelSettings

// Guardar configuraciÃ³n
saveModelSettings(settings: Partial<ModelSettings>): void

// Verificar si completÃ³ setup
hasCompletedSetup(): boolean

// Marcar setup completo
markSetupCompleted(): void

// Guardar modelos predeterminados
saveDefaultChatModel(modelId: string): void
saveDefaultEmbeddingModel(modelId: string): void

// Obtener IDs de modelos predeterminados
getDefaultModelIds(): { chatModelId, embeddingModelId }

// Resetear todo
clearModelSettings(): void
```

**Estructura guardada**:

```typescript
{
  hasCompletedSetup: boolean;
  defaultChatModelId: string | null;
  defaultEmbeddingModelId: string | null;
  deviceProfile?: { hasWebGPU, memoryGB, deviceClass };
  setupCompletedAt?: number;
  lastUpdatedAt: number;
}
```

---

## ğŸ¨ Componentes UI

### 1. `FirstRunWizard.tsx` - Asistente Inicial

**PropÃ³sito**: Guiar al usuario paso a paso en la primera ejecuciÃ³n.

**Pasos del wizard**:

#### Paso 1: Bienvenida
- Logo y tÃ­tulo
- ExplicaciÃ³n breve del sistema
- Ventajas de ejecuciÃ³n local
- BotÃ³n "Comenzar configuraciÃ³n"

#### Paso 2: DetecciÃ³n
- Spinner de carga
- "Analizando tu dispositivo..."
- Ejecuta `detectDeviceProfile()`
- Ejecuta scoring de todos los modelos

#### Paso 3: SelecciÃ³n de Modelos
- Muestra resumen del dispositivo detectado
- Lista de modelos de chat ordenados por score
  - Cada modelo muestra:
    - Nombre y descripciÃ³n
    - Porcentaje de compatibilidad (color-coded)
    - TamaÃ±o, velocidad, calidad
    - Warnings si aplica
    - Emoji de recomendaciÃ³n (âœ¨ excellent, âœ“ good, âš ï¸ usable, âŒ no recomendado)
- Modelo de embeddings (auto-seleccionado)
- Botones: "AtrÃ¡s" | "Cargar modelos seleccionados"

#### Paso 4: Carga
- Progress bars para chat y embedding
- Mensajes de progreso en tiempo real
- Usa callbacks de `WebLLMEngine` / `WllamaEngine`

#### Paso 5: Completado
- Checkmark verde
- "Â¡Todo listo!"
- Auto-cierra en 2 segundos

**Props**:

```typescript
interface FirstRunWizardProps {
  onComplete: () => void;
}
```

---

### 2. `ModelConfigMenu.tsx` - MenÃº de ConfiguraciÃ³n

**PropÃ³sito**: Permitir reconfiguraciÃ³n de modelos en cualquier momento.

**Funcionalidad**:

- BotÃ³n trigger: "Configurar modelos"
- Al hacer click, muestra modal con:
  - Estado actual de modelos cargados
  - Opciones:
    - "Cambiar modelos" â†’ abre wizard
    - "Recargar modelos actuales" â†’ refresh
    - "Resetear configuraciÃ³n" â†’ limpia todo y reinicia wizard

**Estados**:

- Cerrado: Solo muestra botÃ³n
- Abierto: Muestra panel de opciones

**Props**:

```typescript
interface ModelConfigMenuProps {
  onOpenWizard: () => void;
}
```

---

## ğŸ”„ Flujo de Usuario

### Primera EjecuciÃ³n

```
Usuario abre app
    â†“
AppLayout detecta !hasCompletedSetup()
    â†“
Muestra FirstRunWizard
    â†“
1. Welcome screen
    â†“
2. Detectando capacidades...
    â†“
3. Lista de modelos scored
    â†“
Usuario selecciona modelo
    â†“
4. Cargando modelos (progress bars)
    â†“
5. âœ… Completado
    â†“
saveDefaultChatModel(id)
saveDefaultEmbeddingModel(id)
markSetupCompleted()
    â†“
onComplete() â†’ cierra wizard
    â†“
App lista para usar
```

### Ejecuciones Posteriores

```
Usuario abre app
    â†“
AppLayout detecta hasCompletedSetup() == true
    â†“
NO muestra wizard
    â†“
Carga modelos predeterminados automÃ¡ticamente
    â†“
App lista para usar
```

### ReconfiguraciÃ³n Manual

```
Usuario click en "Configurar modelos" (Sidebar)
    â†“
Muestra ModelConfigMenu
    â†“
Usuario elige opciÃ³n:
    â”‚
    â”œâ”€ "Cambiar modelos"
    â”‚   â†“
    â”‚   Abre FirstRunWizard
    â”‚   â†“
    â”‚   Flujo de selecciÃ³n completo
    â”‚
    â”œâ”€ "Recargar actuales"
    â”‚   â†“
    â”‚   Reinicializa engines con mismos modelos
    â”‚
    â””â”€ "Resetear"
        â†“
        clearModelSettings()
        resetAll() engines
        â†“
        Abre FirstRunWizard
```

---

## ğŸ“Š Sistema de Scoring - Detalles

### Ejemplo de CÃ¡lculo

**Dispositivo**: 8GB RAM, WebGPU disponible (tier: medium), 4 cores

**Modelo**: Qwen2.5 1.5B
- sizeGB: 1.0
- requiresWebGPU: false
- minMemoryGB: 2
- preferredMemoryGB: 4

**Scoring**:

```
Base: 100

Memoria:
  - estimatedAvailable: 8 * 0.3 = 2.4GB
  - 2.4GB >= 2GB (min) âœ“
  - 2.4GB < 4GB (preferred) â†’ -20
  Score: 80

WebGPU:
  - Modelo no requiere GPU
  - Device tiene GPU â†’ +0
  Score: 80

Memory usage ratio:
  - 1.0GB / 2.4GB = 0.42 (< 0.7) â†’ +0
  Score: 80

Device class:
  - mid-range + modelo 1GB â†’ +0
  Score: 80

FINAL: 80% â†’ "excellent" âœ¨
```

---

## ğŸš€ Uso y ExtensiÃ³n

### Agregar Nuevo Modelo

1. Edita `src/lib/ai/model-registry.ts`:

```typescript
{
  id: 'nuevo-modelo-id',
  name: 'NuevoModelo-1B',
  displayName: 'Nuevo Modelo 1B (DescripciÃ³n)',
  description: 'DescripciÃ³n tÃ©cnica del modelo',
  type: 'chat',
  engine: 'webllm',
  webllmModelId: 'NuevoModelo-1B-q4f16-MLC',
  ggufUrl: 'https://huggingface.co/...',
  sizeGB: 0.8,
  speed: 'fast',
  quality: 'good',
  quantization: 'q4',
  minMemoryGB: 2,
  preferredMemoryGB: 3,
  requiresWebGPU: false,
  contextSize: 2048,
  tags: ['nuevo', 'experimental']
}
```

2. El modelo aparecerÃ¡ automÃ¡ticamente en el wizard
3. Se scored automÃ¡ticamente segÃºn el dispositivo

### Modificar Algoritmo de Scoring

Edita `src/lib/ai/model-scoring.ts`:

```typescript
export function scoreModel(model: ModelMetadata, device: DeviceProfile): ModelScore {
  let score = 100;

  // Agrega tu lÃ³gica personalizada aquÃ­
  if (model.tags.includes('experimental')) {
    score -= 10; // Penaliza modelos experimentales
  }

  // ... resto del cÃ³digo
}
```

### Cambiar Criterios de DetecciÃ³n

Edita `src/lib/ai/device-profile.ts`:

```typescript
function classifyDevice(memoryGB, hasWebGPU, cores): DeviceClass {
  // Modifica los umbrales segÃºn tus necesidades
  if (hasWebGPU && memoryGB >= 16 && cores >= 8) {
    return 'high-end';
  }
  // ...
}
```

---

## ğŸ§ª Testing

### Probar Primera EjecuciÃ³n

```javascript
// En consola del navegador:
localStorage.removeItem('edge-ai-model-settings');
location.reload();
```

### Ver ConfiguraciÃ³n Actual

```javascript
import { exportSettings } from '@/lib/ai/model-settings';
console.log(exportSettings());
```

### Simular Dispositivo Diferente

Modifica temporalmente `device-profile.ts`:

```typescript
export async function detectDeviceProfile(): Promise<DeviceProfile> {
  // Hardcodea valores para testing
  return {
    hasWebGPU: false,
    memoryGB: 4,
    // ...
  };
}
```

---

## ğŸ“ Notas TÃ©cnicas

### Persistencia

- Usa `localStorage` (clave: `'edge-ai-model-settings'`)
- Estructura JSON simple
- No hay backend, todo es cliente
- Compatible con modo incÃ³gnito (se pierde al cerrar)

### Carga de Modelos

- **Primera vez**: Descarga desde HuggingFace (~1-3 min)
- **Siguientes veces**: Cache del navegador (instantÃ¡neo)
- **Storage**: IndexedDB (WebLLM) o Cache API (Wllama)

### WebGPU vs WASM

| Feature | WebGPU | WASM |
|---------|--------|------|
| Velocidad | âš¡ Muy rÃ¡pida | ğŸ¢ Lenta |
| Compatibilidad | ğŸ”´ Solo Chrome/Edge | ğŸŸ¢ Todos los navegadores |
| Consumo RAM | ğŸŸ¢ Bajo | ğŸ”´ Alto |
| Modelos grandes | âœ… SÃ­ | âŒ DifÃ­cil |

### Recomendaciones

- Dispositivos high-end: Modelos 3B+ con WebGPU
- Dispositivos mid-range: Modelos 1.5B con WebGPU o WASM
- Dispositivos low-end: Modelos 360M-0.5B con WASM

---

## ğŸ› Troubleshooting

### "WebGPU no disponible"
- Actualiza Chrome/Edge a la Ãºltima versiÃ³n
- Verifica flags: `chrome://flags/#enable-unsafe-webgpu`

### "Modelo tarda mucho en cargar"
- Normal la primera vez (descarga)
- Verifica conexiÃ³n a internet
- Comprueba espacio en disco

### "Out of memory"
- Selecciona modelo mÃ¡s pequeÃ±o
- Cierra pestaÃ±as del navegador
- Aumenta RAM del sistema

---

## ğŸ“š Referencias

- [WebLLM Documentation](https://github.com/mlc-ai/web-llm)
- [Wllama Repository](https://github.com/ngxson/wllama)
- [WebGPU Spec](https://www.w3.org/TR/webgpu/)
- [HuggingFace GGUF Models](https://huggingface.co/models?library=gguf)

---

**Ãšltima actualizaciÃ³n**: 2025-12-25
**VersiÃ³n**: 1.0.0
